{"data":{"site":{"siteMetadata":{"title":"5π Consulting","author":"Johannes 'fish' Ziemke"}},"markdownRemark":{"id":"795c08c7-3d65-5716-9b0a-17eb3e7baaae","html":"<p>From legacy infrastructure to over 100 million content moderation decisions per\nday.</p>\n<p>Building an agile cloud native infrastructure for a high velocity AI based\ncontent moderation startup.</p>\n<!--end-->\n<blockquote class=\"testimonial\">\n  \n  <a class=\"gatsby-resp-image-link\" href=\"/static/4ec7be89f6c38590c69feb48b398454f/7a4df/kareem.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n  \n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block;  max-width: 650px; margin-left: auto; margin-right: auto;\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 99.89165763813651%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAUEA//EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAZXbNrJgNV4IoP/EABwQAAICAgMAAAAAAAAAAAAAAAEDAhIABBARMf/aAAgBAQABBQJHVtlYHAlQsZaGD0pjmxARZ//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQMBAT8BH//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQIBAT8BH//EAB0QAAAGAwEAAAAAAAAAAAAAAAABAhARIRIiMXH/2gAIAQEABj8C2GSeNIOSVJsn1qof/8QAHBAAAgMBAAMAAAAAAAAAAAAAAREAITEQQVFx/9oACAEBAAE/IfleooGW3mSvQYNQaVS4jCAa0Yr5QwOpVaENCf/aAAwDAQACAAMAAAAQk88A/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPxAf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPxAf/8QAHRABAAIDAAMBAAAAAAAAAAAAAQARITFREHGBof/aAAgBAQABPxAsFm+kVrcFho54wVXQTpNicjzi5KpY+Vj3HcqIpgbE4xdqKj+JXJTKxWgc6n//2Q==&apos;); background-size: cover; display: block;\">\n      <img class=\"gatsby-resp-image-image\" style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\" alt=\"Kareem Kouddous\" title=\"\" src=\"/static/4ec7be89f6c38590c69feb48b398454f/b80fa/kareem.jpg\" srcset=\"/static/4ec7be89f6c38590c69feb48b398454f/cf410/kareem.jpg 163w,\n/static/4ec7be89f6c38590c69feb48b398454f/62f2a/kareem.jpg 325w,\n/static/4ec7be89f6c38590c69feb48b398454f/b80fa/kareem.jpg 650w,\n/static/4ec7be89f6c38590c69feb48b398454f/7a4df/kareem.jpg 923w\" sizes=\"(max-width: 650px) 100vw, 650px\">\n    </span>\n  </span>\n  \n  </a>\n    \n  <code>Working with Johannes enabled us to dramatically accelerate product\ndevelopment by having the rest of the engineering team focus 100% on feature\ndevelopment, deploying many times a day despite supporting a very high\nthroughput application.\n  </code>\n  <footer><cite>Kareem Kouddous, CTO at Koko AI</cite></footer>\n</blockquote>\n<h2>About Koko</h2>\n<p><a href=\"https://koko.ai\">\n  <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 600px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 14.666666666666666%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAPUlEQVQI12NgwA14gFgBynYAYksom5GBRADToAXEqUAcDMQlQBwDxK5AzMRAJuADYjWoIR5ArAnEMoQ0AQCklgOnayAMsQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n    >\n      <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"Logo\"\n        title=\"\"\n        src=\"/static/1bc80e2cb128767187e1830cdeb8d580/e9f3b/logo-wide.png\"\n        srcset=\"/static/1bc80e2cb128767187e1830cdeb8d580/47931/logo-wide.png 163w,\n/static/1bc80e2cb128767187e1830cdeb8d580/de8a5/logo-wide.png 325w,\n/static/1bc80e2cb128767187e1830cdeb8d580/e9f3b/logo-wide.png 600w\"\n        sizes=\"(max-width: 600px) 100vw, 600px\"\n      />\n    </span>\n  </span>\n  </a></p>\n<p>The Internet can be a scary place. Koko keeps your community safe by using AI to\nidentify bad actors and damaging content. Koko detects issues in real time and\nnotifies your moderation system.</p>\n<p>Koko is already used by several top online communities to support over 100\nmillion moderation decisions per day.</p>\n<h2>Rancher to Kubernetes migration</h2>\n<p>When Koko contacted me, their infrastructure was running on an old version of\n<a href=\"https://rancher.com/\">Rancher</a> which should be replaced by a Kubernetes\ncluster. I’ve migrated all deployment manifests to Kubernetes manifests and\nwrote scripts for <a href=\"https://circleci.com/\">CircleCI</a> to continuously deploy code\nchanges to the cluster. New branches get deployed to their own namespace with\nown ingresses to allow developers to worker independently while also allowing\ncross team and code base feature work.</p>\n<p>To cleanup existing branches, I’ve developed\n<a href=\"https://github.com/itskoko/k8s-ci-purger\">k8s-ci-purger</a> which cleans up\nKubernetes resources on branch deletion.</p>\n<p>Since self-service is paramount, Koko needed a safe and reliable way for\ndevelopers to use internal services. This was solved by using\n<a href=\"https://github.com/bitly/oauth2_proxy\">oauth2_proxy</a> to authenticate against\nGitHub. Additional changes to support Websockets for Jupyter Notebooks were\nadded.</p>\n<h2>kubecfn - Cloudformation Kubernetes Installer</h2>\n<p><img src=\"/kubecfn-2f7d38406a33c80962b9131bc20ee2bf.svg\" alt=\"kubecfn architecture diagram\">\nInitially, Koko used <a href=\"https://github.com/kubernetes/kops\">kops</a> to deploy the\nKubernetes cluster. Customizing Kubernetes component configuration often\nrequired upstream changes in a rapidly evolving code base. That didn’t only\nslowed us down but also caused reliability issues due the dependency on unstable\nversions. After investigating alternatives, which I also <a href=\"https://5pi.de/2017/12/15/production-grade-kubernetes/\">blogged\nabout</a>, I proposed to\ncreate a <a href=\"https://aws.amazon.com/cloudformation/\">Cloudformation</a> based\nKubernetes Installer around\n<a href=\"https://kubernetes.io/docs/setup/independent/\">kubeadm</a>. The safety\nfirst-design gave us the confidence required to quickly iterate by ensuring safe\nrollouts of version and configuration changes.\nThe project was made open source and can be <a href=\"https://github.com/itskoko/kubecfn\">found\nhere</a></p>\n<h2>Argo Machine Learning Pipeline</h2>\n<p>The next thing to solve was how to run machine learning pipelines on the new\ncluster. There are several options but <a href=\"https://github.com/argoproj/argo\">Argo</a>\nseemed like the best fit. Being a generic workflow engine it extends the\nexisting Kubernetes API allowing developers to use the same API and declarative\nmanifests to run the pipelines.</p>\n<p>The custom built Kubernetes installer made it easy to add another GPU-enabled worker\ninstance group that automatically gets scaled up when a Argo pipeline requires\nGPU instances and back to zero after the jobs finished.</p>\n<h2>Autoscaling</h2>\n<p>\n  <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/11142449492391c031ce5b468b20afc4/628b1/autoscaling.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n  \n  <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 650px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 47.71863117870723%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAAsTAAALEwEAmpwYAAABtUlEQVQozy1Su47VMBDNl8BN4syM345fyU1yc1l2kZBAFFQUUFFRUFDzF0jbgYSEREfHB+4EVjqyxvM8PuMmpuzHGOJxWh8EYNdC30L7dOg7TD4ZY4111nmtjTZWKuPD6FyQSjdKW0DZtkKRdW4Ugtxnoz7I/CnVrzl88RDIaK+N6/qBK431nA9AvRiaUuYQUt+DfWv9R4+bvPm+b/dz/RVv/+71d8RJznlNuXIOZ87ziqhSKt7HxodklO+8CO/H+cVC7+h6v+3f1vjDXv8s6acbMqZQw5hObc80az0PQDGVGEvDZLglwxiXYh2Qhpcw3AG9InyD8rUUEtuTAJA+RCLNDxQC205wr4bvTINBqElqBIWtwk7BSYoneNhwRCUZpayU5jGZNLdo2DLOEqlhkMAAyZ5/kkhmgaSUPgr4+hjiEw7nUexTcMlrZ7U1JBUvgANcYoNDZsJ+x+vRrDM34oGkDqbGO0Bq4jKlbY7rlPclb+d8OVCua7kuLExdy7zXaSvn58t0qfOlnp9N01aXm5mHNWEcWXQ/Fq15gRrpPwzbvQAWKYYx8C8as9b2mMzvl4c6rPEDFnxu/b1mv5wAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n    >\n      <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"Autoscaling Dashboard\"\n        title=\"\"\n        src=\"/static/11142449492391c031ce5b468b20afc4/10273/autoscaling.png\"\n        srcset=\"/static/11142449492391c031ce5b468b20afc4/9b14a/autoscaling.png 163w,\n/static/11142449492391c031ce5b468b20afc4/94962/autoscaling.png 325w,\n/static/11142449492391c031ce5b468b20afc4/10273/autoscaling.png 650w,\n/static/11142449492391c031ce5b468b20afc4/2fc6f/autoscaling.png 975w,\n/static/11142449492391c031ce5b468b20afc4/628b1/autoscaling.png 1052w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n      />\n    </span>\n  </span>\n  \n  </a>\n    \nAs in most infrastructures, Koko’s traffic pattern is diurnal with much higher\ntraffic during the (US) day than the night. Due to the nature of the service, it\nfluctuates even more with short peaks and troughs when customers batch process\nworkloads. While Kubernetes provides simple CPU based autoscaling out the box,\nthis wasn’t sufficient to scale up quickly enough while preventing it from scale\ndown too early when a customer briefly stops sending requests.</p>\n<p>To solve that, I’ve introduced the <a href=\"https://prometheus.io/\">Prometheus Monitoring\nSystem</a> and used\nthe\n<a href=\"https://github.com/DirectXMan12/k8s-prometheus-adapter\">k8s-prometheus-adapter</a>\nto provide the metrics as Kubernetes Custom Metrics. This allowed me to create\nscaling rules for rapid scaling up while preventing underprovisioning by looking\nat past traffic patterns.</p>\n<h2>Observability</h2>\n<p>Koko used <a href=\"https://www.datadoghq.com/\">Datadog</a> for monitoring and, once it was\navailable, logging too. Since we weren’t very happy with the service and\nstruggled to integrate custom metrics as well as metrics provided by\ninfrastructure services, we decided to move all our monitoring to Prometheus.\nI’ve introduced <a href=\"https://grafana.org/\">Grafana</a> with statically provisioned and\nCI deployed dashboards for system and infrastructure metrics, while also\nallowing developers to create their own dashboards ad-hoc, allowing for a\nself-service monitoring experience. I’ve built\n<a href=\"https://github.com/itskoko/prometheus-renderer\">prometheus-renderer</a> to render\nalerting expressions to provide graph previews in our slack alerts.</p>\n<p>Since no logging services provided structured logging at a reasonable price,\nI’ve integrated the <a href=\"https://aws.amazon.com/elasticsearch-service/\">AWS Elasticsearch\nService</a> with\n<a href=\"https://fluentbit.io/\">fluent-bit</a> which allowed us to browse, filter and graph\nlogs as well as integrate them into Grafana dashboards.</p>\n<h2>Stream processing</h2>\n<p>\n  <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 650px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 69.140625%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAAsTAAALEwEAmpwYAAACi0lEQVQoz01T207bQBD1l7RpbO96r76s74ljOyZOAk1CwqWCBooAVTSFiDxA6QX1M/oTfehDn/p1nRBUVRqNZmZndo/nHGuO41EqwHw/iKIkDGOlAko4o4IQTtaBhFPGZBDEUZRK6UJxU9EgMUzLRMQwLF3HTcNCTGJmG4g0DYwQwZiCBzNNy/ivAl5zbCfzRVvwSAhBeKbUfKd8O+qEXDqEwryFKYZWRIjFIP6XQqC1g+Biu3Oyk8/76eV2dj0r7g7LxbS4mpT9VDWamBFGMAWj1nPwbBbTelm8mvc/nQ5WR/X96eD+pH97XK+O68fzwTALmjoGeOYT5g1y0yTrdAM7UN5unY22WpO6PellY7C6M6k7s0Eee45uWlI4nNtC2JxvAocze7NFTQrbVaHrBo6jXBULqRARFpEmZvAsZxz277lKeUr5IUxCG2cSIKxfhivR0/We6zPKTQQ7N+HAMBCQAd26gU0T6zpCmAIQeJ8yu6Ej6IRhp2GShmG9bOIXTfzKANosQoWFGUKUExpJDgGMubYdO9xhLFJelYScME3a7sfd8vawt5xWV6NyuTdQNgiA554shNgOvJudOGIUPqFIguu9ajEtVwfVl7f1rBtrvvJ/nL/+vZj8XMz+3Ex/LXY9zqrI//qmujuoPs+H389Gy1HeaKI0VJcHvbNZ93RWne9vjbcSDeQ5H+fXh9X7/e7yqPpwUBCLFGn0eDn+djF6eDd8OBsuj/ugFiEdLiSHDdu247qE8jXsThJ220nZiqpOWrZTjC0h5KYCvpvFsQ8SxmGUtFp54IdJ3ErTbK1t+B86edVqF8CH4waeimDVvh9mRaU8HypAXlMHVaM0bnWrHjCXZXlRdIHzv04jtAKsLOvoAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n    >\n      <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"Stream Processing Dashboard\"\n        title=\"\"\n        src=\"/static/87a6eb80f7df852d72c949c282e58488/10273/streamprocessing.png\"\n        srcset=\"/static/87a6eb80f7df852d72c949c282e58488/9b14a/streamprocessing.png 163w,\n/static/87a6eb80f7df852d72c949c282e58488/94962/streamprocessing.png 325w,\n/static/87a6eb80f7df852d72c949c282e58488/10273/streamprocessing.png 650w,\n/static/87a6eb80f7df852d72c949c282e58488/2fc6f/streamprocessing.png 975w,\n/static/87a6eb80f7df852d72c949c282e58488/92289/streamprocessing.png 1024w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n      />\n    </span>\n  </span>\n  \nWhen Koko’s API receives content to classify, it needs to archive to S3 them for\nrunning machine learning on it. Initially <a href=\"https://aws.amazon.com/kinesis/data-firehose/\">AWS Kinesis\nFirehose</a> was being used for\nthat. That allowed buffering and batching the data, even though further\nprocessing to shard the data was necessary. Since it also doesn’t support <a href=\"https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html\">VPC\nEndpoints</a>\nKoko incurred high traffic costs.</p>\n<p>I’ve proposed and implemented a custom solution by using\n<a href=\"https://www.fluentd.org/\">fluentd</a> and Kubernetes statefulsets to replace\nKinesis Firehose. This reduced Koko’s EC2 traffic costs by 80%. You can read\nmore about the details in <a href=\"/2018/10/31/fluentd-for-data-warehousing-with-athena/\">this blog article</a>.</p>\n<h2>Conclusion</h2>\n<p>Koko’s ability to rapidly and reliably build new features helped it to attract\nsome of the largest social networks.</p>\n<p>I’m proud to have built the infrastructure that allowed Koko to be confident in\nchange and deliver it fast.</p>\n<p>Do you want to accelerate your product development by building upon or migrating\nto modern cloud native infrastructure? <a href=\"/hire-me\">Let me know!</a>.</p>","frontmatter":{"title":"Koko: AI-Powered Community Moderation","date":null,"image":{"childImageSharp":{"fixed":{"base64":"data:image/webp;base64,UklGRrAAAABXRUJQVlA4IKQAAAAwBACdASoUABQAPm0wk0ckIqGhKAqogA2JQA7gBk0Bwd65S9ZbARaFWgAA/rjXf1M6ZEb0VcghgHVq3SO6aj6F1f3jXRwikYu4cJv9swu48PE6+mq55QH+FuGZZXE5DJZyk6YEkeiP97yNbJ5Q+y2X6v//cHV3RZTm3f//Xo//ntTPJ/6ceZEJ6eSk1IX4X3AnG34suvswhUx2/CDaPcG4swAAAA==","width":256,"height":256,"src":"/static/385c89998dfdff6e9859bdab678f9d2d/f2c7a/logo.webp","srcSet":"/static/385c89998dfdff6e9859bdab678f9d2d/f2c7a/logo.webp 1x"}}}}}},"pageContext":{"slug":"/case-studies/koko/","previous":{"fields":{"slug":"/case-studies/styla/"},"frontmatter":{"title":"Styla: Content Experience Engine"}},"next":false}}
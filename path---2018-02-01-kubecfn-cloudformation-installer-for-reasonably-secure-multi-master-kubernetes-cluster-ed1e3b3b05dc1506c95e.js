webpackJsonp([99864164588419],{428:function(e,t){e.exports={data:{site:{siteMetadata:{title:"5π Consulting",author:"Johannes 'fish' Ziemke"}},markdownRemark:{id:"/usr/src/src/pages/2018/02/01/kubecfn-cloudformation-installer-for-reasonably-secure-multi-master-kubernetes-cluster/index.md absPath of file >>> MarkdownRemark",html:'<h1>Introduction</h1>\n<p>These days I’m helping <a href="https://itskoko.com/">koko</a> to build their Kubernetes\ninfrastructure on AWS. Initially, we used kops to deploy the cluster but weren’t\nvery happy. I’ve researched various option and <a href="/2017/12/15/production-grade-kubernetes/">blogged about\nthem</a> earlier.</p>\n<p>tl;dr: There aren’t that many options that are secure, highly available and\ndon’t require buying into a vendor ecosystem.</p>\n<p>kubeadm is the official vendor independent solution to installer Kubernetes.\nWhile it lacks automated setup of multi master clusters, <a href="https://kubernetes.io/docs/setup/independent/high-availability/">it’s\npossible</a>.</p>\n<p>To have a reliable and reproducable way to build clusters, we decided to create\n<a href="https://aws.amazon.com/cloudformation/">Cloudformation</a> templates to fully\nautomate this setup.</p>\n<p>All this is opend sourced and available on <a href="https://github.com/itskoko/kubecfn">https://github.com/itskoko/kubecfn</a></p>\n<h2>Architecture</h2>\n<p><img src="/kubecfn-2f7d38406a33c80962b9131bc20ee2bf.svg" alt="kubecfn architecture diagram">\nThe cluster consists of multiple components required for the cluster.</p>\n<h3>Offline key generation</h3>\n<p>The first step to create a new cluster is <a href="https://github.com/itskoko/kubecfn/blob/e3cf1d21db72ca5467ac6f43abc02c5871fd444a/Makefile#L84">generating the TLS keys for etcd and\nkubeadm</a>.\nThese credentials get uploaded to S3 and the instances get a IAM instance\nprofile with a <a href="https://github.com/itskoko/kubecfn/blob/e3cf1d21db72ca5467ac6f43abc02c5871fd444a/kubernetes.yaml#L759">policy allowing it to download\nthem</a>.</p>\n<h3>Controller Instances</h3>\n<p>The controller instances are managed by an autoscaling group.</p>\n<p>They are running etcd and the controller components like the apiserver,\nscheduler and controller manager.\n<a href="https://coreos.com/ignition/docs/latest/">ignition</a> downloads the <a href="https://github.com/itskoko/kubecfn/blob/e3cf1d21db72ca5467ac6f43abc02c5871fd444a/kubernetes.yaml#L859">TLS\nkeys</a>\nand <a href="https://github.com/itskoko/kubecfn/blob/e3cf1d21db72ca5467ac6f43abc02c5871fd444a/kubernetes.yaml#L978">sets up systemd units for kubelet and\netcd</a>.</p>\n<p>On initial cluster creation (<code class="language-text">make create-cluster</code>), the ClusterState flag is\nset to <code class="language-text">new</code>, which enables etcd bootstrapping. To find the other etcd peers,\nwe’re using SRV record based <a href="https://coreos.com/etcd/docs/latest/v2/clustering.html#dns-discovery">DNS\nDiscovery</a>.\nThis option give us one way to bootstap, as well as dynamically add and remove\nmembers. On the other hand, the ‘static’ and ‘etcd’ discovery can be only used\nfor initial cluster configuration.</p>\n<p>Unfortunately AWS can’t automatically add DNS records for instances in an\nautoscaling group. To solve this, we’re using a lambda to update a route53 zone\n(see next section).</p>\n<p>Once etcd is up, <code class="language-text">kubeadm init</code> creates the manifests and keys for the\ncontroller components but use the pre-generated keys for the CA generated in the\nfirst step. This makes sure all controller keys are signed with this trusted CA.</p>\n<p><a href="https://github.com/itskoko/kubecfn/blob/e3cf1d21db72ca5467ac6f43abc02c5871fd444a/kubernetes.yaml#L1158">An ELB</a>\nin front of the apiservers provide a stable endpoint for both the workers as\nwell as users of the cluster.</p>\n<h3>Route53 Lambda</h3>\n<p>The cluster creates it’s own Route53 zone, which needs to be a subdomain of the\ngiven <code class="language-text">ParentZoneID</code> parameter. Beside a record pointing to the apiserver ELB,\nthis zone is updated <a href="https://github.com/itskoko/kubecfn/blob/e3cf1d21db72ca5467ac6f43abc02c5871fd444a/kubernetes.yaml#L643">by a\nLambda</a>.</p>\n<p>Each time a controller instances get added or removed by the autoscaling group,\nthe lambda gets triggered and adds/removes DNS records for etcd discovery.</p>\n<h3>Workers</h3>\n<p>The worker setup is straight forward. It’s also managed by an autoscaling group.\nThe ignition config downloads credentials for the kubelet from S3</p>\n<h3>Conclusion and Caveats</h3>\n<p>kubecfn wasn’t build by a big team nor as an end in itself. We focused on making\nit easy to maintain, reliable and fail gracefully. That means there are some\n<a href="https://github.com/itskoko/kubecfn/labels/automation">rough edges around\nautomation</a>. The security\n<a href="https://github.com/itskoko/kubecfn/labels/security">could be improved further</a>\nand I’m not very happy with the whole concept of IAM instance profiles which\neffectively grants these privileges to every process running on a host. We\nmitigate this by installing\n<a href="https://github.com/itskoko/kubecfn/blob/e3cf1d21db72ca5467ac6f43abc02c5871fd444a/manifests/kube2iam.yaml">kube2iam</a>\nbut this isn’t a robust as something like this should be. Unfortunately it’s\ncurrent best practice and there isn’t an easy way to improve. Let me know if you\nknow a better way.</p>\n<p>There is also <a href="https://github.com/itskoko/kubecfn/blob/e3cf1d21db72ca5467ac6f43abc02c5871fd444a/kubernetes.yaml#L247">the nasy\nworkaround</a>\nof patching the kube-proxy configmap after <code class="language-text">kubeadm init</code> which requires\nupstream fixes.</p>\n<p>That being said, thanks to CloudFormation with primitives like\n<a href="/2015/04/27/cloudformation-driven-consul-in-autoscalinggroup/">WaitOnResourceSignals</a>\nand features like <a href="https://github.com/itskoko/kubecfn#dry-run">Change Sets</a>, I\nfeel more comfortable operating this cluster than I was with any other installer\nI used in the past.</p>',frontmatter:{title:"kubecfn: Cloudformation installer for reasonably secure multi-master Kubernetes Cluster",date:"February 01, 2018"}}},pathContext:{slug:"/2018/02/01/kubecfn-cloudformation-installer-for-reasonably-secure-multi-master-kubernetes-cluster/",previous:{fields:{slug:"/2017/12/15/production-grade-kubernetes/"},frontmatter:{title:"Production Grade Kubernetes"}},next:{fields:{slug:"/2018/02/17/found-severe-azure-kubernetes-bug-and-aint-even-got-a-lousy-t-shirt/"},frontmatter:{title:"Found severe Azure Kubernetes Bug but ain't even got a lousy T-Shirt"}}}}}});
//# sourceMappingURL=path---2018-02-01-kubecfn-cloudformation-installer-for-reasonably-secure-multi-master-kubernetes-cluster-ed1e3b3b05dc1506c95e.js.map
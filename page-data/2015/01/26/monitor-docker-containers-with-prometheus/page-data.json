{"componentChunkName":"component---src-templates-blog-post-js","path":"/2015/01/26/monitor-docker-containers-with-prometheus/","result":{"data":{"site":{"siteMetadata":{"title":"5π Consulting","author":"Johannes 'fish' Ziemke"}},"markdownRemark":{"id":"03114194-fba2-536f-9cfa-d2d5ce7afeac","html":"<h3 id=\"monitoring-docker\" style=\"position:relative;\"><a href=\"#monitoring-docker\" aria-label=\"monitoring docker permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Monitoring Docker</h3>\n<p>Running all your services in containers makes it possible to get in-depth resource and performance characteristics, since every container runs in their own cgroup and the Linux kernel provides us with all kind of useful metrics.</p>\n<p>Although there are a few other Docker monitoring tools out there, I’ll show you why I think that SoundCloud’s <a href=\"https://developers.soundcloud.com/blog/prometheus-monitoring-at-soundcloud\">newly released</a> <a href=\"https://prometheus.github.io/\">Prometheus</a> is a perfect fit for monitoring container-based infrastructures.</p>\n<p>Prometheus features a highly dimensional <a href=\"http://prometheus.github.io/docs/concepts/data_model/\">data model</a> in which a time series is identified by a metric name and a set of key-value pairs. A flexible <a href=\"http://prometheus.github.io/docs/querying/basics/\">query language</a> allows querying and graphing this data. It features advanced <a href=\"http://prometheus.github.io/docs/concepts/metric_types/\">metric types</a> like summaries, building <a href=\"http://prometheus.github.io/docs/querying/functions/#rate()\">rates</a> from totals over specified time spans or <a href=\"http://prometheus.github.io/docs/querying/rules/\">alerting</a> on any expression and has no dependencies, making it a dependable system for debugging during outages.</p>\n<p>I will focus on why especially the data model and query language makes it such a good fit in a containerized, dynamic infrastructure where you think in clusters of services instead of single instances and servers as cattle instead of pets.</p>\n<h3 id=\"classic-approach\" style=\"position:relative;\"><a href=\"#classic-approach\" aria-label=\"classic approach permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Classic Approach</h3>\n<p>Let’s say you want to monitor the memory usage of your containers. Without support for dimensional data, such a metric for the container named <code class=\"language-text\">webapp123</code> might be called <code class=\"language-text\">container_memory_usage_bytes_webapp123</code>.</p>\n<p>But what if you want to show the memory usage of all your <code class=\"language-text\">webapp123</code> containers? More advanced monitoring solutions like <a href=\"https://github.com/graphite-project\">graphite</a> support that. It features a hierarchic, tree-like data model in which such metric might be called <code class=\"language-text\">container.memory_usage_bytes.webapp123</code>. Now you can use wildcards like <code class=\"language-text\">container.memory_usage_bytes.webapp*</code> to graph the memory usage of all your ‘webapp’ containers. Graphite also supports functions like <code class=\"language-text\">sum()</code> to aggregate the memory usage of your application across all your machines by using an expression like <code class=\"language-text\">sum(container.memory_usage_bytes.webapp*)</code>.</p>\n<p>That’s all great and very useful, but limited. What if you don’t want to aggregate all containers with a given name but with a given image? Or you want to compare the deployments to your canary with those on your prod machines?</p>\n<p>It’s possible to come up with a hierarchy for each use case, but not one to support them all. And reality shows, you often don’t know in advance which questions you need to answer once things go dark and you start investigating.</p>\n<h3 id=\"prometheus\" style=\"position:relative;\"><a href=\"#prometheus\" aria-label=\"prometheus permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Prometheus</h3>\n<p>With Prometheus’s support for dimensional data, you can have global and straightforward metric names like <code class=\"language-text\">container_memory_usage_bytes</code> with multiple dimensions to identify the specific instances of your service.</p>\n<p>I’ve created a simple <a href=\"https://github.com/docker-infra/container_exporter\">container-exporter</a> to gather Docker Container metrics and expose them for Prometheus to consume. This exporter uses the container’s name, id and image as dimensions. Additional per-exporter dimension can be set in the <code class=\"language-text\">prometheus.conf</code>.\nIf you use the metric name directly as a query expression, it will return all time series with their labels for this metric name:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">container_memory_usage_bytes{env=\"prod\",id=\"23f731ee29ae12fef1ef6726e2fce60e5e37342ee9e35cb47e3c7a24422f9e88\",instance=\"http://1.2.3.4:9088/metrics\",job=\"container-exporter\",name=\"haproxy-exporter-int\",image=\"prom/haproxy-exporter:latest\"}\t11468800.000000\ncontainer_memory_usage_bytes{env=\"prod\",id=\"57690ddfd3bb954d59b2d9dcd7379b308fbe999bce057951aa3d45211c0b5f8c\",instance=\"http://1.2.3.5:9088/metrics\",job=\"container-exporter\",name=\"haproxy-exporter\",image=\"prom/haproxy-exporter:latest\"}\t16809984.000000\ncontainer_memory_usage_bytes{env=\"prod\",id=\"907ac267ebb3299af08a276e4ea6fd7bf3cb26632889d9394900adc832a302b4\",instance=\"http://1.2.3.2:9088/metrics\",job=\"container-exporter\",name=\"node-exporter\",image=\"prom/container-exporter:latest\"}\n...\n...</code></pre></div>\n<p>If you run lot of containers, this looks something like this:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/065a19374aba5620f406a9361ff35444/2e237/container_memory_usage_bytes.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 71.16564417177914%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAAsSAAALEgHS3X78AAACKklEQVR42nWS+04aQRSH92H7Dn2a/tukrUULKg2mSCRYWu+wsywLVbsoAruw7M7l7NwbRo02aX/5Mpk5OZl8c/GiKLrqXfkuCKHpdCqEAIDyOQClEnyxpm/eDd9+uOZiE2ttFEVeulwuV8skSdI0xRgTQsr/RJZcuD0ppcaYMAy9OP6dpun9/V0cx1E09Pv9AKHgOc9LhBDy/X4QoMFgEARoPB63Wi0vTdNVli1Xa0JZkq5m83m2zikDygATOl8k2TrHmBaYTqezPMdcSAaltTYMhx4AAOeYsYKSJ4jDTQgDCiUBKCjFlD425ARzKfu+71FKpRRaCWu1Ndoa40aHNVpLJUuthNHKGm0cWqunC2OMKa2VsdpY9YqXpTb27xizqYxGIw8Y0JKtWV4AxkAKwK/BgHNW5Kx4VSGkBGUtGgw8ypiS0mjlxJybmztD5SSlVC8IKUpOrdWDEG20td4c71HO2H9L/kcbIMuz28n4ZjJOVrPp9Pp+dpcTvFjEs4cxlORuFo9uwkUyiSc3D/M5ocT9MOP7vieFup1E51fNYNg9uWxfBMcnF43u2bde+PO83+6cNi77zUu/3T07CMYnaNQ9R+3e8McFatcPKh5jIDjwkhY4B6CCg3tyLDgXHAheC85cA+OcAuQlFITmjGX93qknSt77hT42q1ut/Z2jvb3jWq2zv9OuVzv1audr7XujclTfbu/XOruVw+pWs1o5rH5qftk+brzf/fwHeYED+eOBJtMAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"container_memory_usage_bytes.png\"\n        title=\"\"\n        src=\"/static/065a19374aba5620f406a9361ff35444/a6d36/container_memory_usage_bytes.png\"\n        srcset=\"/static/065a19374aba5620f406a9361ff35444/222b7/container_memory_usage_bytes.png 163w,\n/static/065a19374aba5620f406a9361ff35444/ff46a/container_memory_usage_bytes.png 325w,\n/static/065a19374aba5620f406a9361ff35444/a6d36/container_memory_usage_bytes.png 650w,\n/static/065a19374aba5620f406a9361ff35444/2e237/container_memory_usage_bytes.png 790w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>To help you make sense of this data, you can filter and/or aggregate these metrics</p>\n<h4 id=\"slice--dice\" style=\"position:relative;\"><a href=\"#slice--dice\" aria-label=\"slice  dice permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Slice &#x26; Dice</h4>\n<p>With Prometheus’s query language, you can slice and dice data by any dimension you want. If you’re interested in all containers with a given name, you can use an expression like <code class=\"language-text\">container_memory_usage_bytes{name=\"consul-server\"}</code>, which would show only the time series for which <code class=\"language-text\">name == \"consul-server\"</code>.\nPrometheus also supports regular expressions, so instead of matching the full script you can do <code class=\"language-text\">container_memory_usage_bytes{name=~\"^consul\"}</code>, which would show something like this:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/2a7a760e3618b0ac5e2f4d9ba57082c5/0fcea/container_memory_usage_bytes_consul.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 66.25766871165644%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAAsSAAALEgHS3X78AAABdElEQVR42oVSW27bMBDUtXuMnqM36DHaQILV+iMwHFuREdN87ZNkQTKWg6BFBwNylsvHcMnBGHNezpfLZV3X6/XNGBNC8N7nhpRyKeUa9Mu356/fT6WUXAdKE3noi5flfF4WY8ztdnPOWWudc76hCucwhOi9vaestd77YX19Xdf19HI6Ho/TNI3jOM/zr4ZxHKdpquE8P/38sdvt9vv974Z5ng+HwxBjsNYiIjP3XUUkNXjvAQCRAtCbubmIwBpJAgqxllIGVQHiUIc4kgBX4SJ5qGEkBVZkJWQOQYLvZIj1zimlnFIvQCmPYjwUU4aYCd9r1dq6Kuch50wI4B0Ej3eCd5smiKSCqijSCSLEXG2LCBJRUlLZiMJdcFJOiVXTB1+Pk3v3T9vbbE3KslH6yTlnlRYTP3IfNANRREFW0Y3C0qut3KYysdQtG+9aRdo/S/mvtrXhv7Y/32KrtiixIlCoz1wfFZEjcuyaBDbdU+03UMnlD6OR8TxGq1rCAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"container_memory_usage_bytes_consul.png\"\n        title=\"\"\n        src=\"/static/2a7a760e3618b0ac5e2f4d9ba57082c5/a6d36/container_memory_usage_bytes_consul.png\"\n        srcset=\"/static/2a7a760e3618b0ac5e2f4d9ba57082c5/222b7/container_memory_usage_bytes_consul.png 163w,\n/static/2a7a760e3618b0ac5e2f4d9ba57082c5/ff46a/container_memory_usage_bytes_consul.png 325w,\n/static/2a7a760e3618b0ac5e2f4d9ba57082c5/a6d36/container_memory_usage_bytes_consul.png 650w,\n/static/2a7a760e3618b0ac5e2f4d9ba57082c5/0fcea/container_memory_usage_bytes_consul.png 851w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>You can use any other dimension for filtering as well, so you can get metrics about all containers on a given host, in a given environment or zone.</p>\n<h4 id=\"aggregation\" style=\"position:relative;\"><a href=\"#aggregation\" aria-label=\"aggregation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Aggregation</h4>\n<p>Similar to Graphite, Prometheus supports aggregation functions but due to its dimensions this gets even more powerful. Summing up the memory usage of all your “consul-*” works as expected with <code class=\"language-text\">sum(container_memory_usage_bytes{name=~\"^consul\"})</code>.</p>\n<p>Now let’s say you want to see the difference in average memory usage between your ‘consul’ and ‘consul-server’ containers. This is achieved by providing the dimensions to keep in the aggregated result like this <code class=\"language-text\">avg(container_memory_usage_bytes{name=~\"^consul\"}) by (name)</code>:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 650px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/b0d3d92bda3203b73787ae1285ca75bc/b2cef/container_memory_usage_bytes_consul_by_name-1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 76.07361963190185%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAIAAABr+ngCAAAACXBIWXMAAAsSAAALEgHS3X78AAABnklEQVR42q1SSy8EQRCe/0oicVphbThJHNw4E3FzwE3EwWmzv0AsY81hyAZZO6O359HP6gfdw+xYGydfKpN69Ff1VU8HaIJGo1GSJOl7ihBK0zTLsjwvMMYTjBnj1pqMys7p087Fs23AGBPkeT4ejx05TYuiKMqSUkoooR7sG5Ry4nOEkKrKGQvePF6eX4bDYRiGt3e3g8Egeoiihyj0GHj0+zcuH7nkfXgfhmEcx0FZlhhjSqkQAmOcZ7mUkktGRJFMRihLcjopGH5LX4syU1rVmp1s5VFvorTkQIRi2mhXt878YW2tvelft1Zaq2uty6tza20AAFxSrkhlFa1uP70e7XyEUK/X63a78WPsyH4wGN/bf90k8xO1zqlApZxsAFDgZTt1s7QZsjGmWhMAvsgA0Cz/Qa53mU7+H3KzxRxfa/sd/iBrVzLao/kAZ97jvAtr/GetFDCmhFBCAOeSUcW5CzkX1PsudL7WOrDWnp0cb3Za21tbG+vto4MDLYUSvDJHnueD4F/kw8P95aWFdruzsLi4u7f3W/BcfMr+AMeIVXPOyfG6AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"container_memory_usage_bytes_consul_by_name\"\n        title=\"\"\n        src=\"/static/b0d3d92bda3203b73787ae1285ca75bc/a6d36/container_memory_usage_bytes_consul_by_name-1.png\"\n        srcset=\"/static/b0d3d92bda3203b73787ae1285ca75bc/222b7/container_memory_usage_bytes_consul_by_name-1.png 163w,\n/static/b0d3d92bda3203b73787ae1285ca75bc/ff46a/container_memory_usage_bytes_consul_by_name-1.png 325w,\n/static/b0d3d92bda3203b73787ae1285ca75bc/a6d36/container_memory_usage_bytes_consul_by_name-1.png 650w,\n/static/b0d3d92bda3203b73787ae1285ca75bc/b2cef/container_memory_usage_bytes_consul_by_name-1.png 847w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>If you have services in multiple zones and configure the zone name as an additional label pair, you can also keep that dimension to show the memory usage per name and zone by using an expression like <code class=\"language-text\">avg(container_memory_usage_bytes{name=~\"^consul\"}) by (name,zone)</code>.</p>\n<h4 id=\"using-prometheus--container-exporter\" style=\"position:relative;\"><a href=\"#using-prometheus--container-exporter\" aria-label=\"using prometheus  container exporter permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Using Prometheus + Container-Exporter</h4>\n<p>As you know, I like to run everything in containers, including the container-exporter and Prometheus itself. Running the <a href=\"https://github.com/docker-infra/container_exporter\">container-exporter</a> should be as easy as this:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">docker run -p 8080:8080 -v /sys/fs/cgroup:/cgroup \\\n           -v /var/run/docker.sock:/var/run/docker.sock prom/container-exporter</code></pre></div>\n<p>Now you need to install Prometheus. For that refer to the <a href=\"http://prometheus.github.io/docs/introduction/install/\">official documentation</a>. To make Prometheus pull the metrics from the container-exporter, you need to add it as a target to the configuration. For example:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">job: {\n  name: \"container-exporter\"\n  scrape_interval: \"1m\"\n  target_group: {\n  \tlabels: {\n\t    label: {\n    \t\tname: \"zone\"\n        \tvalue: \"us-east-1\"\n\t    }\n        label: {\n        \tname: \"env\"\n            value: \"prod\"\n        }\n    }\n    target: \"http://1.2.3.4:8080/metrics\"\n  }\n}</code></pre></div>\n<p>Now rebuild your image as described in the documentation and start it. Prometheus should now poll your container-exporter every 60s.</p>\n<h3 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h3>\n<p>Because of Prometheus flexibility, its performance and minimal requirements, it’s the monitoring system of my choice.\nThis is why I introduced Prometheus beginning last year at Docker where we use it as our primary monitoring system.</p>","frontmatter":{"title":"Monitor Docker Containers with Prometheus","date":"January 26, 2015","image":{"childImageSharp":{"fixed":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAAsSAAALEgHS3X78AAAC+ElEQVR42o1R227bRhDlf7U/VtuNJLsPeSyExPF3pEEfaiBAnKqydbPEiytbsiSTFEnxslySe19yWVB13ARxihwcDM7MnFns7GpXV1fD4bB/ednr9XRdz/M8+wZACktWvD5f/fhy+MPL4bkeaL7veb7neR6EMMsyVan6G1D7zu2Wvh3A3wYwgFKL4xgAkABACEEIFUWBvwRC6DONBSd1ReuKUoo113Xn8/l6s7FubizLMk3TMAxd/4+WZRmmaZiPqWGYhmnNdGM207UkiVMA8jxbrVbLxcKxbc/3oiiMGjRxuVi4rrPdbne7XRRFruvc3d66rpumQNslEBYkQzSIUy9MIpCnBSkIf6IXJgksEogyRAvCE4jcIEogwkxqXHDGOeOUciJLSSjCuMCkoIxi3ERZSiEEF1xIwRhlnDaCU0KxxhjmnAhBpRSc47KUVSnLZoBVVSklYwwzhigtGENCECHY3syFYJpS6qsveabybFETZfU/w5VSslKirORzNi1GICUIUgwJbiLFTUoeBcAZwCnAICxA+skA9/6UIE2pkgrEBH4i5Z9SScpK1rWqayVL/pmN/GvTvtrli2sr1bBSqnp25+95nv0R6rH19BxVpeUo80Mvx0VdK4zSPM84F0rVZSkEzSuJ9yMVFyJJY1mKUrIUQsGZqkptqvensw8TczK7uRxN/5wZvdl8cu8sVytjOHk/03uBv1hs5h/+etsfX4yvL6Z6XzdHU31kzQ3tdjlaO9bfd33dGs/XU/N+PBy96w3+GOh9e7fuTy/eX51fDn+/31zf3A0nxsXA+njvjO/syfX8owahD6GfxA5CIINBnu1A4sI0LPIEFSHKIxC7WbolGOZZkOchwUmB4gJFqIg1OwqW3tZY2w+7rRtt3chzQt+OAjvyH0LfDn032T1Eu0ZHoRP5Tuiv3c3KWbmBox10W4fd9ovXnfZp+/js6ORNq33aOuy22m+OWw1POmfHP5/+ctBtHb3qdM6OOq9eHHY7B92Tn37t/ANdukTQSQexzQAAAABJRU5ErkJggg==","width":790,"height":790,"src":"/static/065a19374aba5620f406a9361ff35444/fc072/container_memory_usage_bytes.png","srcSet":"/static/065a19374aba5620f406a9361ff35444/fc072/container_memory_usage_bytes.png 1x"}}}}}},"pageContext":{"slug":"/2015/01/26/monitor-docker-containers-with-prometheus/","previous":{"fields":{"slug":"/2015/01/08/containerized-infrastructure/"},"frontmatter":{"title":"Containerize your Infrastructure"}},"next":{"fields":{"slug":"/2015/01/27/find-ghosts-in-your-docker-images/"},"frontmatter":{"title":"Find GHOSTs in your Docker images"}}}},"staticQueryHashes":[],"slicesMap":{}}
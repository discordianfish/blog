webpackJsonp([0xefbd5ea46e68],{510:function(e,a){e.exports={data:{site:{siteMetadata:{title:"5π - fish's blog",author:"Johannes 'fish' Ziemke"}},markdownRemark:{id:"/usr/src/src/pages/2017/11/09/use-prometheus-vector-matching-to-get-kubernetes-utilization-across-any-pod-label/index.md absPath of file >>> MarkdownRemark",html:'<p>Prometheus was designed for dynamic environments like Kubernetes. Its powerful\nservice discovery and query language allows you to answer all kind of questions\nthat come up while operating a Kubernetes cluster.</p>\n<p>This flexibility comes with a somewhat steeper learning curve than some\nalternatives and hosted services, with <a href="https://prometheus.io/docs/prometheus/latest/querying/operators/#vector-matching">Vector\nMatching</a>\nbeing one of the more advanced topics.</p>\n<p>I’m not going into the details which the excellent <a href="https://prometheus.io/docs/prometheus/latest/querying/operators/#vector-matching">Prometheus\nDocumentation</a>\nhas already covered but walk you through some useful queries to get resource\nutilization in a Kubernetes cluster.</p>\n<h2>Aggregated memory usage per label</h2>\n<p>Kubernetes provides a <code>container_memory_usage_bytes</code> metric reflecting each pods\nmemory usage, e.g:</p>\n<div class="gatsby-highlight">\n      <pre class="language-none"><code>...\ncontainer_memory_usage_bytes{beta_kubernetes_io_arch="amd64",beta_kubernetes_io_fluentd_ds_ready="true",beta_kubernetes_io_instance_type="g1-small",beta_kubernetes_io_os="linux",cloud_google_com_gke_nodepool="small-preemptible",cloud_google_com_gke_preemptible="true",container_name="POD",failure_domain_beta_kubernetes_io_region="us-east1",failure_domain_beta_kubernetes_io_zone="us-east1-c",id="/kubepods/burstable/pod13d4221c-c484-11e7-bff5-42010af0018b/67e5bb069ab9881ff8a55b8628ef4935b0d1ace09c18df20db059522bdfd5b7d",image="gcr.io/google_containers/pause-amd64:3.0",instance="gke-latency-at-small-preemptible-0c981b61-9489",job="kubernetes-cadvisor",kubernetes_io_hostname="gke-latency-at-small-preemptible-0c981b61-9489",name="k8s_POD_latency-api-971504058-jzs5h_default_13d4221c-c484-11e7-bff5-42010af0018b_0",namespace="default",pod_name="latency-api-971504058-jzs5h"}\t389120\ncontainer_memory_usage_bytes{beta_kubernetes_io_arch="amd64",beta_kubernetes_io_fluentd_ds_ready="true",beta_kubernetes_io_instance_type="g1-small",beta_kubernetes_io_os="linux",cloud_google_com_gke_nodepool="small-preemptible",cloud_google_com_gke_preemptible="true",container_name="POD",failure_domain_beta_kubernetes_io_region="us-east1",failure_domain_beta_kubernetes_io_zone="us-east1-c",id="/kubepods/burstable/pod81d0f651-c500-11e7-bff5-42010af0018b/309e05b118e618122c70ccf88538d13ca41c3b5a770d5d67882426854391c23c",image="gcr.io/google_containers/pause-amd64:3.0",instance="gke-latency-at-small-preemptible-0c981b61-9489",job="kubernetes-cadvisor",kubernetes_io_hostname="gke-latency-at-small-preemptible-0c981b61-9489",name="k8s_POD_latency-api-971504058-gszpw_default_81d0f651-c500-11e7-bff5-42010af0018b_0",namespace="default",pod_name="latency-api-971504058-gszpw"}\t372736\ncontainer_memory_usage_bytes{beta_kubernetes_io_arch="amd64",beta_kubernetes_io_fluentd_ds_ready="true",beta_kubernetes_io_instance_type="g1-small",beta_kubernetes_io_os="linux",cloud_google_com_gke_nodepool="small-preemptible",cloud_google_com_gke_preemptible="true",container_name="latency-api",failure_domain_beta_kubernetes_io_region="us-east1",failure_domain_beta_kubernetes_io_zone="us-east1-c",id="/kubepods/burstable/pod13d4221c-c484-11e7-bff5-42010af0018b/497e6fdf2217771cb3f52e6fef93734d023f0e7f23f92c58d22139fc18dc5f13",image="registry.gitlab.com/latency.at/latencyat@sha256:8ea057e064b64cc9c8459a68ef3f6d0fc26169b4f57aef193831779e1fe713d4",instance="gke-latency-at-small-preemptible-0c981b61-9489",job="kubernetes-cadvisor",kubernetes_io_hostname="gke-latency-at-small-preemptible-0c981b61-9489",name="k8s_latency-api_latency-api-971504058-jzs5h_default_13d4221c-c484-11e7-bff5-42010af0018b_1",namespace="default",pod_name="latency-api-971504058-jzs5h"}\t11014144\ncontainer_memory_usage_bytes{beta_kubernetes_io_arch="amd64",beta_kubernetes_io_fluentd_ds_ready="true",beta_kubernetes_io_instance_type="g1-small",beta_kubernetes_io_os="linux",cloud_google_com_gke_nodepool="small-preemptible",cloud_google_com_gke_preemptible="true",container_name="latency-api",failure_domain_beta_kubernetes_io_region="us-east1",failure_domain_beta_kubernetes_io_zone="us-east1-c",id="/kubepods/burstable/pod81d0f651-c500-11e7-bff5-42010af0018b/7b438a8e9df0cf1ab29d067fd36c97099f9f5e7e9257f6187c5be6bff846a62c",image="registry.gitlab.com/latency.at/latencyat@sha256:8ea057e064b64cc9c8459a68ef3f6d0fc26169b4f57aef193831779e1fe713d4",instance="gke-latency-at-small-preemptible-0c981b61-9489",job="kubernetes-cadvisor",kubernetes_io_hostname="gke-latency-at-small-preemptible-0c981b61-9489",name="k8s_latency-api_latency-api-971504058-gszpw_default_81d0f651-c500-11e7-bff5-42010af0018b_0",namespace="default",pod_name="latency-api-971504058-gszpw"}\t11448320\n...</code></pre>\n      </div>\n<p>Unfortunately it doesn’t contain the pod labels. For that there is the\n<code>kube_pod_labels</code> though which includes a static timeseries with all labels and\nthe pod name. This metric is provided by\n<a href="https://github.com/kubernetes/kube-state-metrics">kube-state-metrics</a>.</p>\n<p>We can use it to look up the labels for the pod from the\ntimeseries (<code>pod_name="latency-api-971504058-jzs5h"</code>):</p>\n<div class="gatsby-highlight">\n      <pre class="language-none"><code>kube_pod_labels{instance="10.116.0.12:8080",job="kubernetes-service-endpoints",k8s_app="kube-state-metrics",kubernetes_name="kube-state-metrics",kubernetes_namespace="kube-system",label_app="latency-api",label_pod_template_hash="971504058",namespace="default",pod="latency-api-971504058-jzs5h"} 1\nkube_pod_labels{instance="10.116.1.26:8080",job="kubernetes-service-endpoints",k8s_app="kube-state-metrics",kubernetes_name="kube-state-metrics",kubernetes_namespace="kube-system",label_app="latency-api",label_pod_template_hash="971504058",namespace="default",pod="latency-api-971504058-jzs5h"} 1</code></pre>\n      </div>\n<p>Both metrics can be merged by using vector matching. We get this metric twice\nbecause there are two instances of kube-state-metrics running. So before we\ncontinue further, we aggregate both. Since they should be identical, we can use\nmin/max to aggregate. Since we later want to aggregate on <code>label_app</code>, we need\nto keep that label. We also need to keep the <code>pod</code> label to join both metrics\non. We can preserve them by specifying them in the BY clause. Since the pod\nlabel is called <code>pod</code> in <code>kube_pod_labels</code> but <code>pod_name</code> in\n<code>container_memory_usage_bytes</code>, we need to also use label_replace to rename the\nlabel. This gives us:</p>\n<div class="gatsby-highlight">\n      <pre class="language-none"><code>max by (pod_name,label_app) (\n  label_replace(kube_pod_labels{label_app!=""},"pod_name","$1","pod","(.*)")\n)</code></pre>\n      </div>\n<p>Which returns something like:</p>\n<div class="gatsby-highlight">\n      <pre class="language-none"><code>...\n{label_app="latency-api",pod_name="latency-api-971504058-n8k6d"}  1\n{label_app="latency-api",pod_name="latency-api-971504058-jzs5h"}  1\n...</code></pre>\n      </div>\n<p>Now we can use vector matching to join <code>container_memory_usage_bytes</code> with the\nresult of our expression. We use the <code>*</code> operator which effectivly is a no-op\nsince it will multiply the memory usage by the matched timeseries value in\n<code>kube_pod_labels</code> which is always 1.</p>\n<p>We need to specify <code>group_left</code> because there are multiple\n<code>container_memory_usage_bytes</code> timeseries for each pod, one for each container.\nSince we want to preserve the <code>label_app</code> label, we specify it as argument to <code>group_left</code>.</p>\n<p>This gives us:</p>\n<div class="gatsby-highlight">\n      <pre class="language-none"><code>  container_memory_usage_bytes * on (pod_name) group_left(label_app)\n  max by (pod_name,label_app) (\n    label_replace(kube_pod_labels{label_app!=""},"pod_name","$1","pod","(.*)")\n  )</code></pre>\n      </div>\n<p>To aggregated the memory usage of all your pods, summed by a <code>k8s-app</code> label you\ncan use the following expression:</p>\n<div class="gatsby-highlight">\n      <pre class="language-none"><code>sum by (label_app,namespace) (\n  container_memory_usage_bytes * on (pod_name) group_left(label_app)\n  max by (pod_name,label_app) (\n    label_replace(kube_pod_labels{label_app!=""},"pod_name","$1","pod","(.*)")\n  )\n)</code></pre>\n      </div>\n<p>\n  <a\n    class="gatsby-resp-image-link"\n    href="/static/mem_per_app-0f0a37acb794c49740014ce150e3ae1f-0a8a9.png"\n    style="display: block"\n    target="_blank"\n    rel="noopener"\n  >\n  \n  <span\n    class="gatsby-resp-image-wrapper"\n    style="position: relative; display: block; ; max-width: 590px; margin-left: auto; margin-right: auto;"\n  >\n    <span\n      class="gatsby-resp-image-background-image"\n      style="padding-bottom: 79.38144329896907%; position: relative; bottom: 0; left: 0; background-image: url(\'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsSAAALEgHS3X78AAACRElEQVQ4y5VTW24TQRDcg/jLf/6whOADJ1Yi28hPya/4Br4HCgQQQoJTBCkovgC5gi9BHNsB4pAEvLszs48punv9iKMEhZFqe2Z7pra6ptex1iIMQyilJGqt4fs+XNfFfD6HMWaVZ/Ca857ngc/ehcOPwASCOI4RRZGASYIgkDm/5zVjmQuDZH9sYyGSOcHhF9pX0J7CclhKwGI97O3FeghJRB/TAYzSiMIIzkqNNtCuokhJT8P4Wg7YW8x8OKZDgTIbiLmKaKlwIZUPhmZZYgR/7opqJg/IN+35Ugkr4XLDhR08oihcYKFQa9rIMKTMKIFSHnzPxfXPGZTvCZI8fSAg0jCQPXxOa1/AlTpsPN+cfcAji/v9W9trN/Ynt8ztQGoMtUISk3nA0EbyEZtO8wTkL4M7Q0DvaA976djY4ub3DS5+zTC7usSlYIaLK17PqN/m+ONeY/JjjPH5GJPvU4oTjM5H+DY5xel0hLPpGUYUPeXDYanD4RCHnw8xGAwEx6t4jKMvRzg5+brwlbxij8lDbbTMZW2SdUSXKYSv9l/i2dMnKBZL2N3dFRQKBeRyOaTTadRqNWmLxwwhfP3mHfL5HbRaTdTrdTQaDUGxWEQmk0Gn01m1yH2/28avx5vevj9AfmdLSCqVCqrVqqhihalUCu12+z8JD4hwe1sImWxJuiy52WxKS9xtkwdL3ifC51ukkMplMlZXKpWEMJvNotvtStM+mvDTxw94USpgb68nfjFarRZ6vR7K5TL6/f5Gyf8afwEmkHH4kHQEfAAAAABJRU5ErkJggg==\'); background-size: cover; display: block;"\n    >\n      <img\n        class="gatsby-resp-image-image"\n        style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;"\n        alt="mem_per_app"\n        title=""\n        src="/static/mem_per_app-0f0a37acb794c49740014ce150e3ae1f-fb8a0.png"\n        srcset="/static/mem_per_app-0f0a37acb794c49740014ce150e3ae1f-1a291.png 148w,\n/static/mem_per_app-0f0a37acb794c49740014ce150e3ae1f-2bc4a.png 295w,\n/static/mem_per_app-0f0a37acb794c49740014ce150e3ae1f-fb8a0.png 590w,\n/static/mem_per_app-0f0a37acb794c49740014ce150e3ae1f-526de.png 885w,\n/static/mem_per_app-0f0a37acb794c49740014ce150e3ae1f-0a8a9.png 970w"\n        sizes="(max-width: 590px) 100vw, 590px"\n      />\n    </span>\n  </span>\n  \n  </a>\n    </p>\n<h2>CPU and IO usage per label</h2>\n<p>Now that we know how to join the <code>kube_pod_labels</code> metric with cadvisor metrics,\nwe can figure out usage of other resources too.</p>\n<h3>CPU</h3>\n<div class="gatsby-highlight">\n      <pre class="language-none"><code>sum by (label_app,namespace) (\n  rate(container_cpu_usage_seconds_total[2m]) * on (pod_name) group_left(label_app)\n  max by (pod_name,label_app) (\n    label_replace(kube_pod_labels{label_app!=""},"pod_name","$1","pod","(.*)")\n  )\n)</code></pre>\n      </div>\n<p>\n  <a\n    class="gatsby-resp-image-link"\n    href="/static/cpu_per_app-ee8bde4b930678ada8505a9cc8e749ba-0a8a9.png"\n    style="display: block"\n    target="_blank"\n    rel="noopener"\n  >\n  \n  <span\n    class="gatsby-resp-image-wrapper"\n    style="position: relative; display: block; ; max-width: 590px; margin-left: auto; margin-right: auto;"\n  >\n    <span\n      class="gatsby-resp-image-background-image"\n      style="padding-bottom: 79.38144329896907%; position: relative; bottom: 0; left: 0; background-image: url(\'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsSAAALEgHS3X78AAACR0lEQVQ4y5WTzW4SURTHeZCu2LEgUTfSEkAwUCDhq7wB72Eaq8aY6FvYpCZ04cpAxYWbmhJakKqgViENlE7LlzPADF9/7zkwLSWEtDf555577p3fPeeeM4bxeIzBYIBut8uzqqpsK4oCWZahaRr7e70ei9a03+l0QN/OyzAcDq8+IptmUr/fZ5Fv1q/btDcajXg9Oxv0AzTohmVjfl+PamITdHANXBT+vCiCRX4a/b7KYiCFfxugHuAi4L/2mXjXxvIIaWhaR6Si8VpTFVGQhjivTf19UUSZdVbNQ5Evbr6hqnY5Lf1NJkBF3FwXoBYkqYha7VhUXxIVbwm10WyUcXHxE+XSvjjXnACVtgylJUOqVtC6rPNaqlTQlOoon2RQ+JbCaekQvwop/C5+Qulkf6ovPBe/7+HH8Qd0CUipyO0GGlIVdamCy/Myzmt/2a5Lpyj9SaNQ+Iz81xQymQSyR0nksgmk0++RO0ogn0sie0j+jyJlAaS0DtIH2N5+i93dOCsej1/ZOzvvkEjuceFUlXqT+lE803Ak5tHEnor7kICbm0/w4P49OJ1O2O122Gx2OBwOWCwWGI1GeL1ebtybvTjbk9c2A58+ewGr1YZgMACfzwe/38+iC0wmE8Lh8A3gMjHw+cstWG2rDPF4PFhfX+eoKMKVlRWEQqE7ArcEcG2NgQTToXrKgUBgpp2W/56TNxTAh6siQpEuwSg6l8vFQLPZjEgkcuv/nYFvXr/CY9cjbGxE+b1IwWAQ0WgUbrcbsVhsQVEWj//2cGesm4V6ogAAAABJRU5ErkJggg==\'); background-size: cover; display: block;"\n    >\n      <img\n        class="gatsby-resp-image-image"\n        style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;"\n        alt="cpu_per_app"\n        title=""\n        src="/static/cpu_per_app-ee8bde4b930678ada8505a9cc8e749ba-fb8a0.png"\n        srcset="/static/cpu_per_app-ee8bde4b930678ada8505a9cc8e749ba-1a291.png 148w,\n/static/cpu_per_app-ee8bde4b930678ada8505a9cc8e749ba-2bc4a.png 295w,\n/static/cpu_per_app-ee8bde4b930678ada8505a9cc8e749ba-fb8a0.png 590w,\n/static/cpu_per_app-ee8bde4b930678ada8505a9cc8e749ba-526de.png 885w,\n/static/cpu_per_app-ee8bde4b930678ada8505a9cc8e749ba-0a8a9.png 970w"\n        sizes="(max-width: 590px) 100vw, 590px"\n      />\n    </span>\n  </span>\n  \n  </a>\n    </p>\n<h3>Disk IO</h3>\n<p>I wanted to show you some disk IO stats too. Unfortunately these are\n<a href="https://github.com/kubernetes/kubernetes/issues/55397">broken</a> once\n<a href="https://github.com/kubernetes/kubernetes/issues/55398">again</a> in Kubernetes.</p>\n<h3>Network</h3>\n<div class="gatsby-highlight">\n      <pre class="language-none"><code>sum by (label_app,namespace) (\n  rate(container_network_transmit_bytes_total[2m]) * on (pod_name) group_left(label_app)\n  max by (pod_name,label_app) (\n    label_replace(kube_pod_labels{label_app!=""},"pod_name","$1","pod","(.*)")\n  )\n)</code></pre>\n      </div>\n<p>\n  <a\n    class="gatsby-resp-image-link"\n    href="/static/net_per_app-9cdc5336080b286047c358a645a9a8ed-0a8a9.png"\n    style="display: block"\n    target="_blank"\n    rel="noopener"\n  >\n  \n  <span\n    class="gatsby-resp-image-wrapper"\n    style="position: relative; display: block; ; max-width: 590px; margin-left: auto; margin-right: auto;"\n  >\n    <span\n      class="gatsby-resp-image-background-image"\n      style="padding-bottom: 79.38144329896907%; position: relative; bottom: 0; left: 0; background-image: url(\'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsSAAALEgHS3X78AAACEElEQVQ4y5VTS24aQRCdg7BixwIp8ibYyOCZiG/EAOYG3CNCdhJFkZJbIDbmAJyBcySb2HyGAYb59XNVDT0GTCKnpZqu7q5+9epVjxHHMYIgwHa7RRiG2O124q/Xa7iuC9/3Zd/zPDFe8/lms4FS6pUZHKwvRVEkMyfQdrh/GsNkeH04G/xh00PFdEBM/ncwOwFkZM4mlOkgZmauI76iAJ4jb4uY4s6VqE0TMzRd3oQGXC33WRPm4cpBTGVKkj0bnUzfO2LImpwF3EsROEsCDKD25bEfbtwU6AhQN0WXHAW+AOCg5MBZSKI0xk9iUlkOS+aF7lDMPgX7SwKg6CiM5JK/mENF4UsHuOMkw+lINQw5O11QrCX5EZXDmjErVo0TLJ8esZg9wSHwxeMfzH//Et+Zz2ieYUUx3FyDkafTKYbDIcYPDxiPtY1lHo1GmEwmIotH3eaHz37yTv3EuCqymJ6cAA4Gn3Bx8Q6maaFUKomVy2UUCgVks1nU63WSJX7TexTAu89fUSxew7ZbaDQa+NhsoklmmiZyuRw6nY7o/NJVxc7p005+PXa/fLtH8fpSQKrVKmq1mrBihplMBu12+wjwX5YA3hPg1ZUAMpgG1SW3Wq3091SvmJ0peUCA7y+JIZXLYMzOsiwBzOfz6Ha78vjfDPjzx3d8sG5we9sTvdhs20av10OlUkG/3z/R8O/jGTNndueoXiN5AAAAAElFTkSuQmCC\'); background-size: cover; display: block;"\n    >\n      <img\n        class="gatsby-resp-image-image"\n        style="width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;"\n        alt="net_per_app"\n        title=""\n        src="/static/net_per_app-9cdc5336080b286047c358a645a9a8ed-fb8a0.png"\n        srcset="/static/net_per_app-9cdc5336080b286047c358a645a9a8ed-1a291.png 148w,\n/static/net_per_app-9cdc5336080b286047c358a645a9a8ed-2bc4a.png 295w,\n/static/net_per_app-9cdc5336080b286047c358a645a9a8ed-fb8a0.png 590w,\n/static/net_per_app-9cdc5336080b286047c358a645a9a8ed-526de.png 885w,\n/static/net_per_app-9cdc5336080b286047c358a645a9a8ed-0a8a9.png 970w"\n        sizes="(max-width: 590px) 100vw, 590px"\n      />\n    </span>\n  </span>\n  \n  </a>\n    </p>',frontmatter:{title:"Use Prometheus Vector Matching to get Kubernetes Utilization across any Pod Label",date:"2017-11-08T23:00:00.000Z"}}},pathContext:{slug:"/2017/11/09/use-prometheus-vector-matching-to-get-kubernetes-utilization-across-any-pod-label/",previous:{fields:{slug:"/2017/04/17/selenium-webdriver-chromedriver-nightwatch-chrome-headless/"},frontmatter:{title:"Frontend Testing Zoo - Or, Nightwatch without Selenium"}},next:{fields:{slug:"/2017/12/15/production-grade-kubernetes/"},frontmatter:{title:"Production Grade Kubernetes"}}}}}});
//# sourceMappingURL=path---2017-11-09-use-prometheus-vector-matching-to-get-kubernetes-utilization-across-any-pod-label-0f18eef791eb11be0317.js.map